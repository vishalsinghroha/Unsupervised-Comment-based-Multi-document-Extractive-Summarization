import math
import operator
from functools import reduce
from random import uniform
import numpy as np
from collections import defaultdict
import numpy as np
import operator as op
# from differential_evolution_functions import Mutation,Repair_Solution,Select_Random
from joblib.numpy_pickle_utils import xrange
from nltk.tokenize import word_tokenize
from cluster_validity_indices.anti_redundancy import Sent_to_sent
# from cluster_validity_indices.sent_to_caption import Sent_to_caption

import random

data = np.array
matrix = np.array


class MBDE():
    def __init__(self, Mating_Pool, population, current_solution_index, current_solution, SS_WMD_Matrix,
                 MAX_reader_attention_matrix,
                 MAX_density_based_score_matrix,
                 MAX_objective4_matrix,
                 MAX_objective5_matrix,
                 MAX_TWEET_length_matrix, max_len_solution, b=6, CR=0.8, F=0.8,
                 min_sent_in_summary=3, max_sent_in_summary=8):
        """
        :param Mating_Pool: Generated mating pool for current solution
        :param population: Population containing solutions
        :param current_solution_index: Current solution index in population
        :param current_solution: Current solution vector
        :param b: MBDE Control parameter
        :param CR: #MBDE Control parameter-Crossover Probability
        :param F: #MBDE Control parameter
        :param SS_WMD_Matrix: Sentence to Sentence WMD matrix
        :param MAX_reader_attention_matrix: Reader attention value of each tweet
        :param MAX_density_based_score_matrix: Density based score of each tweet
        :param MAX_objectie4_matrix: Reader attention with tf-idf score of each tweet
        :param MAX_objectie5_matrix: Named entity score of each tweet
        :param min_tweet_in_summary: Minimum number of tweets that can be in summary
        :param max_tweet_in_summary: Maximum number of tweets that can be in summary
        """
        self.population = population
        self.current_solution = current_solution
        self.current_solution_index = current_solution_index
        self.Q = Mating_Pool
        self.F = F
        self.b = b
        self.r = 3
        self.CR = CR
        self.SS_WMD_Matrix = SS_WMD_Matrix
        self.MAX_reader_attention_matrix = MAX_reader_attention_matrix
        self.MAX_density_based_score_matrix = MAX_density_based_score_matrix
        self.MAX_objective4_matrix = MAX_objective4_matrix
        self.MAX_objective5_matrix = MAX_objective5_matrix
        self.MAX_TWEET_Length_matrix = MAX_TWEET_length_matrix
        self.Minimum_sent_in_summary = min_sent_in_summary
        self.Maximum_sent_in_summary = max_sent_in_summary
        self.max_length_solution = max_len_solution

    def ncr(self):
        """
        :param n: length of mating pool
        :param r: number of solution we need to take to make combinations
        :return: no. of possible combinations
        """
        n1 = len(self.Q)
        r1 = min(self.r, n1 - self.r)
        if r1 == 0: return 1
        numer = reduce(op.mul, xrange(n1, n1 - r1, -1))
        denom = reduce(op.mul, xrange(1, r1 + 1))
        return numer // denom

    """This function return the combinations"""

    def prob(self, parent1, parent2, parent3):
        """
        :param parent1: First random solution from mating pool
        :param parent2: second random solution from mating pool
        :param parent3: third random solution from mating pool
        :return: probability of each component
        """

        p_list = []
        i = 0
        n2 = len(parent1)
        while (i < n2):
            x1 = parent1[i]
            x2 = parent2[i]
            x3 = parent3[i]
            p = float(1) / (
                        1 + math.exp((((2 * self.b * (x1 + (self.F * (x2 - x3) - .5))) / (1 + (2 * self.F))) * (-1))))
            p_list.append(p)
            i += 1
        # print 'Probability list in function: \n\n',p_list      # probability list is generated
        return p_list

    def mutation(self, prob_list):
        """
        :param prob_list: probability list generated by prob(parent1, parent2, parent3, b=6, F=0.8) function
        :return: mutant vector
        """
        i = 0
        p_list = prob_list
        mutant = np.random.randint(0, 1, (len(p_list)))

        while (i < len(p_list)):
            rand = random.uniform(0, 1)
            # print 'random no = ',rand
            if rand <= p_list[i]:
                mutant[i] = 1
            else:
                mutant[i] = 0
            i += 1
        # print 'generated Mutant : \n\n',mutant      #Mutant is generated
        return mutant

    """THis function generates a new solution using crossover"""

    def crossover(self, mutant):
        """
        :param mutant: Mutant for generated in the mutation function
        :return: generates a mutated new solution
        """
        j = 0
        # CR = .2
        crossover = np.random.randint(0, 1, (len(mutant)))
        while (j < len(mutant)):
            aa = self.current_solution
            tar_bit = aa[j]  # self.population[self.current_solution_index, j]
            mut_bit = mutant[j]
            # print 'target bit : ',tar_bit
            # print 'mutant bit : ',mut_bit
            randj = random.uniform(0, 1)
            randi = random.randint(0, len(mutant))
            # print 'randj :',randj
            # print 'randi :',randi
            if randj <= self.CR or j == randi:
                crossover[j] = mut_bit
            else:
                crossover[j] = tar_bit
            j += 1

        # print 'generated Trial : ',crossover      #Trial is generated
        return crossover

    def one_count(self, trial):
        """
        :param trial:  trial vector generated using croosover function
        :return: count the number of ones in trial vector
        """
        # print "type of trial solution : ", type(trial), type(trial.tolist())

        ones_count = trial.tolist().count(1)
        return ones_count

    def Generate(self):
        """
        :param Q: Mating pool
        :param population: Archive population
        :param i: current solution index
        :param x: current solution
        :param max_solution_length: maximum length of the solutions
        :param b: constant
        :param CR: cross-over probability
        :return: New solution
        """
        total_combination = self.ncr()
        count_comination = 1
        # Unique=[]
        # mp=uniform(0,1)
        trial_list = []
        word_len = []
        while count_comination <= total_combination:
            my_randoms = random.sample(xrange(0, len(self.Q)), 3)
            # print( "random solution no. choosen for {0}th solution (combination {1}) :".format(self.current_solution_index, count_comination), my_randoms)
            all_solution_vector = []
            for ww in self.population:
                # print "ind :", ww
                all_solution_vector.append(ww.features)

            p1 = all_solution_vector[self.Q[my_randoms[0]]]
            p2 = all_solution_vector[self.Q[my_randoms[1]]]
            p3 = all_solution_vector[self.Q[my_randoms[2]]]

            probability = self.prob(p1, p2, p3)  # probability vector
            mutant_vector = self.mutation(probability)  # binary vector
            trial_sol = self.crossover(mutant_vector)  # Trial Generated
            ones_count = self.one_count(trial_sol)  # number of ones in generated trial solution
            # print "ones count  :", ones_count
            word_len.append(ones_count)
            trial_list.append(trial_sol)

            count_comination += 1

        solutions_within_range = []  # solution is within minimum and maximum number of sentences to be in the summary
        no_of_ones_in_solution_within_ranges = []
        for j in range(len(word_len)):
            if word_len[j] <= self.Maximum_sent_in_summary and word_len[j] >= self.Minimum_sent_in_summary:
                if ( len(str(solutions_within_range).split() ) + len(str(trial_list[j]).split() ) ) <= 125:
                    solutions_within_range.append(trial_list[j])
                    no_of_ones_in_solution_within_ranges.append(word_len[j])

        if len(solutions_within_range) > 0 and random.uniform(0, 1) < 0.8:
            # print("new solution generated using SOM")
            tot_sol_leng = len(solutions_within_range)
            rand_no = random.randint(0, tot_sol_leng - 1)
            return [solutions_within_range[0]], [no_of_ones_in_solution_within_ranges[0]]
            # except:
        elif random.uniform(0, 1) < 0.8:
            # print("New solution generated using sorted average tweet length objective value of a solution")
            for kk in range(len(word_len)):

                if random.uniform(0, 1) < 0.5:
                    solution = trial_list[kk]
                    new_solution = np.zeros(self.max_length_solution)
                    sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for which there is 1 in the solution
                    for jj in range(len(solution)):
                        if solution[jj] == 1:
                            sentence_objectives.append(self.MAX_TWEET_Length_matrix[jj])
                        else:
                            sentence_objectives.append(-100 + self.MAX_TWEET_Length_matrix[jj])
                    sorted_objective_list = sorted(range(len(sentence_objectives)),
                                                   key=lambda k: sentence_objectives[k],
                                                   reverse=True)  # sort the tweets in reverse order and return the indices
                    # print("sorted list :", sorted_objective_list)
                    x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                    no_of_ones_in_solution_within_ranges.append(x)
                    counter = 0
                    while (x > 0):
                        new_solution[sorted_objective_list[counter]] = 1
                        counter += 1
                        x -= 1
                    # no_of_ones_in_solution_within_ranges.append(x)
                    solutions_within_range.append(new_solution.tolist())

                elif random.uniform(0, 1) < 0.4:
                #else:
                    solution = trial_list[kk]
                    new_solution = np.zeros(self.max_length_solution)
                    sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                    for jj in range(len(solution)):
                        if solution[jj] == 1:
                            sentence_objectives.append(self.MAX_reader_attention_matrix[jj])
                        else:
                            sentence_objectives.append(-100 + self.MAX_reader_attention_matrix[jj])
                    sorted_objective_list = sorted(range(len(sentence_objectives)),
                                                   key=lambda k: sentence_objectives[k],
                                                   reverse=True)  # sort the tweets in reverse order and return the indices
                    # print("sorted list :", sorted_objective_list)
                    x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                    no_of_ones_in_solution_within_ranges.append(x)
                    counter = 0
                    while (x > 0):
                        new_solution[sorted_objective_list[counter]] = 1
                        counter += 1
                        x -= 1
                    # no_of_ones_in_solution_within_ranges.append(x)
                    solutions_within_range.append(new_solution.tolist())

                elif random.uniform(0, 1) < 0.3:
                #else:
                    solution = trial_list[kk]
                    new_solution = np.zeros(self.max_length_solution)
                    sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                    for jj in range(len(solution)):
                        if solution[jj] == 1:
                            sentence_objectives.append(self.MAX_density_based_score_matrix[jj])
                        else:
                            sentence_objectives.append(-100 + self.MAX_density_based_score_matrix[jj])
                    sorted_objective_list = sorted(range(len(sentence_objectives)),
                                                   key=lambda k: sentence_objectives[k],
                                                   reverse=True)  # sort the tweets in reverse order and return the indices
                    # print("sorted list :", sorted_objective_list)
                    x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                    no_of_ones_in_solution_within_ranges.append(x)
                    counter = 0
                    while (x > 0):
                        new_solution[sorted_objective_list[counter]] = 1
                        counter += 1
                        x -= 1
                    # no_of_ones_in_solution_within_ranges.append(x)
                    solutions_within_range.append(new_solution.tolist())

                elif random.uniform(0, 1) < 0.3:
                #else:
                    solution = trial_list[kk]
                    new_solution = np.zeros(self.max_length_solution)
                    sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                    for jj in range(len(solution)):
                        if solution[jj] == 1:
                            sentence_objectives.append(self.MAX_objective4_matrix[jj])
                        else:
                            sentence_objectives.append(-100 + self.MAX_objective4_matrix[jj])
                    sorted_objective_list = sorted(range(len(sentence_objectives)),
                                                   key=lambda k: sentence_objectives[k],
                                                   reverse=True)  # sort the tweets in reverse order and return the indices
                    # print("sorted list :", sorted_objective_list)
                    x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                    no_of_ones_in_solution_within_ranges.append(x)
                    counter = 0
                    while (x > 0):
                        new_solution[sorted_objective_list[counter]] = 1
                        counter += 1
                        x -= 1
                    # no_of_ones_in_solution_within_ranges.append(x)
                    solutions_within_range.append(new_solution.tolist())

                else:
                    solution = trial_list[kk]
                    new_solution = np.zeros(self.max_length_solution)
                    sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                    for jj in range(len(solution)):
                        if solution[jj] == 1:
                            sentence_objectives.append(self.MAX_objective5_matrix[jj])
                        else:
                            sentence_objectives.append(-100 + self.MAX_objective5_matrix[jj])
                    sorted_objective_list = sorted(range(len(sentence_objectives)),
                                                   key=lambda k: sentence_objectives[k],
                                                   reverse=True)  # sort the tweets in reverse order and return the indices
                    # print("sorted list :", sorted_objective_list)
                    x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                    no_of_ones_in_solution_within_ranges.append(x)
                    counter = 0
                    while (x > 0):
                        new_solution[sorted_objective_list[counter]] = 1
                        counter += 1
                        x -= 1
                    # no_of_ones_in_solution_within_ranges.append(x)
                    solutions_within_range.append(new_solution.tolist())
            # tot_sol_leng = len(solutions_within_range)
            # rand_no = random.randint(0, tot_sol_leng)

            return [solutions_within_range[0]], [no_of_ones_in_solution_within_ranges[0]]

        else:
            if random.uniform(0, 1) < 0.5:
                new_solution = np.zeros(self.max_length_solution)
                sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                for jj in range(len(new_solution)):
                    sentence_objectives.append(self.MAX_TWEET_Length_matrix[jj])

                sorted_objective_list = sorted(range(len(sentence_objectives)),
                                               key=lambda k: sentence_objectives[k],
                                               reverse=True)  # sort the sentence to caption similarity in reverse order and return the indices
                x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                no_of_ones_in_solution_within_ranges.append(x)
                counter = 0
                while (x > 0):
                    new_solution[sorted_objective_list[counter]] = 1
                    counter += 1
                    x -= 1
                # no_of_ones_in_solution_within_ranges.append(x)
                solutions_within_range.append(new_solution.tolist())
            elif random.uniform(0, 1) < 0.4:
            #else:
                new_solution = np.zeros(self.max_length_solution)
                sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                for jj in range(len(new_solution)):
                    sentence_objectives.append(self.MAX_reader_attention_matrix[jj])

                sorted_objective_list = sorted(range(len(sentence_objectives)),
                                               key=lambda k: sentence_objectives[k],
                                               reverse=True)  # sort the sentence to caption similarity in reverse order and return the indices
                x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                no_of_ones_in_solution_within_ranges.append(x)
                counter = 0
                while (x > 0):
                    new_solution[sorted_objective_list[counter]] = 1
                    counter += 1
                    x -= 1
                # no_of_ones_in_solution_within_ranges.append(x)
                solutions_within_range.append(new_solution.tolist())
            elif random.uniform(0, 1) < 0.3:
            #else:
                new_solution = np.zeros(self.max_length_solution)
                sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                for jj in range(len(new_solution)):
                    sentence_objectives.append(self.MAX_density_based_score_matrix[jj])

                sorted_objective_list = sorted(range(len(sentence_objectives)),
                                               key=lambda k: sentence_objectives[k],
                                               reverse=True)  # sort the sentence to caption similarity in reverse order and return the indices
                x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                no_of_ones_in_solution_within_ranges.append(x)
                counter = 0
                while (x > 0):
                    new_solution[sorted_objective_list[counter]] = 1
                    counter += 1
                    x -= 1
                # no_of_ones_in_solution_within_ranges.append(x)
                solutions_within_range.append(new_solution.tolist())

            elif random.uniform(0, 1) < 0.3:
            #else:
                new_solution = np.zeros(self.max_length_solution)
                sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                for jj in range(len(new_solution)):
                    sentence_objectives.append(self.MAX_objective4_matrix[jj])

                sorted_objective_list = sorted(range(len(sentence_objectives)),
                                               key=lambda k: sentence_objectives[k],
                                               reverse=True)  # sort the sentence to caption similarity in reverse order and return the indices
                x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                no_of_ones_in_solution_within_ranges.append(x)
                counter = 0
                while (x > 0):
                    new_solution[sorted_objective_list[counter]] = 1
                    counter += 1
                    x -= 1
                # no_of_ones_in_solution_within_ranges.append(x)
                solutions_within_range.append(new_solution.tolist())
            else:
                new_solution = np.zeros(self.max_length_solution)
                sentence_objectives = []  # store the value of sentence to caption similarity of those sentences for whihc there is 1 in the solution
                for jj in range(len(new_solution)):
                    sentence_objectives.append(self.MAX_objective5_matrix[jj])

                sorted_objective_list = sorted(range(len(sentence_objectives)),
                                               key=lambda k: sentence_objectives[k],
                                               reverse=True)  # sort the sentence to caption similarity in reverse order and return the indices
                x = random.randint(self.Minimum_sent_in_summary, self.Maximum_sent_in_summary)
                no_of_ones_in_solution_within_ranges.append(x)
                counter = 0
                while (x > 0):
                    new_solution[sorted_objective_list[counter]] = 1
                    counter += 1
                    x -= 1
                # no_of_ones_in_solution_within_ranges.append(x)
                solutions_within_range.append(new_solution.tolist())

            return [solutions_within_range[0]], [no_of_ones_in_solution_within_ranges[0]]

class MatingPool_Generation():
    def __init__(self):
        pass

    def eu_dist(self, inp_winning_neuron_index, neuron_weights):
        '''
        This function takes two arguments i.e. index of a particular and the neuron set and returns a list of ED between that particular neuron and other neurons weight vectors
        '''
        """        
        :param inp_winning_neuron_index:  winning neuron index for a current solution
        :param neuron_weights: trained SOM neuron's weight vectors
        :return: returns a list of Euclidean Distance between that winning neurons' weight and other neurons's weights
        """

        i = 0
        distnace_list = []
        numner_of_neurons = len(neuron_weights)
        while (i < numner_of_neurons):
            dist1 = np.linalg.norm(
                neuron_weights[inp_winning_neuron_index] - neuron_weights[i])  # Calculating ED between Individual[i]
            distnace_list.append(dist1)
            i = i + 1
        return distnace_list
        # Fetching Minimum ED

    def mating_pool_generation(self, H, L, solution_no, neuron_weight, pop_length, beta=0.8):
        """
        :param H: Number of solutions in mating pool of each neuron (size of H<=no. of neuron in Lattice)
        :param L: mapping neuron indices correspond to solutions in population
        :param i: current solution no.
        :param x: current solution
        :param matrix: neuron weight matrix
        :param beta: threshold probability for generating mating pool
        :return: mating pool of current solution x
        """
        winning_neuron_index = L[solution_no]  ##winning neuron index correspond to current solution
        distnace_list_winning_and_other_neurons = self.eu_dist(winning_neuron_index, neuron_weight)
        sorted_x = sorted(range(len(distnace_list_winning_and_other_neurons)),
                          key=lambda k: distnace_list_winning_and_other_neurons[k])
        # sorted_x=sorted(distnace_list_winning_and_other_neurons)
        counter = 0
        mating_pool = []
        flag = 0
        if uniform(0, 1) < beta:  # and counter < H + 1:
            for k in sorted_x:
                if counter < H + 1:
                    # H+1 is because it will add itself in mating pool list which we need to remove to make the mating pool size as H.
                    found_solution_index = L.index(k)
                    mating_pool.insert(counter, found_solution_index)
                    counter += 1

            if len(mating_pool) == H + 1 and solution_no in mating_pool:
                # print("Mating pool generating using SOM ")
                mating_pool.remove(solution_no)
                return np.asarray(mating_pool), flag

        else:
            # print "Random probability is greater than Beta for this neuron therefore assign population as the mating pool for neuron {0}".format(i)
            mating_pool = list(np.arange(0, pop_length))
            flag = 1
            if solution_no in mating_pool:
                mating_pool.remove(solution_no)
            # print  "Mating pool for solution {} in population".format(i),mating_pool
            return np.asarray(mating_pool), flag